Fine tunning BERT:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ml-mipt/ml-mipt/blob/advanced/week05_BERT_and_LDA/week05_BERT_Fine_Tunning.ipynb)

Simple notebook on LDA:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ml-mipt/ml-mipt/blob/advanced/week05_BERT_and_LDA/week05_Intro_to_topic_modeling.ipynb)



__Further readings__:
* [en] The Illustrated BERT [blog post](http://jalammar.github.io/illustrated-bert/)

* [en] Google AI Blog [post about open sourcing BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)

* [en] OpenAI blog post [Better Language Models
and Their Implications (GPT-2)](https://openai.com/blog/better-language-models/)

* [en] One more [blog post explaining BERT](https://yashuseth.blog/2019/06/12/bert-explained-faqs-understand-bert-working/)

* [en] Great PyTorch library: [pytorch-transformers](https://github.com/huggingface/transformers)

* [en] Most recent (for 04.10.2019) [post about GPT-2 in OpenAI blog](https://openai.com/blog/fine-tuning-gpt-2/)